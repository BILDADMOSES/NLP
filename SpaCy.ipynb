{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style = 'text-align: center'>Intoduction to SpaCy</p>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy has several language models available, including advanced German and Chinese implementations.\n",
    "\n",
    "- English : *en_core_web_sm*\n",
    "- Spanish : *es_core_news_sm*\n",
    "- German : *de_core_news_sm*\n",
    "- French : *fr_core_news_sm*\n",
    "- Dutch : *nl_core_news_sm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a new document by parsing a string into the NLP variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple Inc. is based in Cupertino, California, and it was founded by Steve Jobs.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spaCy, the Doc object, which represents a processed text, provides access to various attributes and properties that allow you to access linguistic annotations and information about the text. Here are some of the commonly used attributes and properties of the Doc object:\n",
    "\n",
    "**text**: The original text of the document.\n",
    "\n",
    "**ents**: A list of named entities found in the text.\n",
    "\n",
    "**sents**: A list of sentence objects in the document.\n",
    "\n",
    "**tokens**: A list of token objects, where each token represents a word or punctuation mark in the text.\n",
    "\n",
    "**noun_chunks**: A list of noun chunks or phrases in the text.\n",
    "\n",
    "**vector**: The document's vector representation, if a word vectors model is available.\n",
    "\n",
    "**vector_norm**: The L2 norm of the document's vector.\n",
    "\n",
    "**is_parsed**: A Boolean value indicating whether the text has been syntactically parsed.\n",
    "\n",
    "**is_tagged**: A Boolean value indicating whether part-of-speech tagging has been performed.\n",
    "\n",
    "**is_nered**: A Boolean value indicating whether named entity recognition (NER) has been performed.\n",
    "\n",
    "**has_annotation**: A Boolean value indicating whether the document has any linguistic annotations.\n",
    "\n",
    "**user_data**: A dictionary where custom data can be stored.\n",
    "\n",
    "**vocab**: The vocabulary of the language model used for tokenization and linguistic analysis.\n",
    "\n",
    "**lang**: The language of the document.\n",
    "\n",
    "**cats**: The document's category labels if text classification is performed.\n",
    "\n",
    "**similarity()**: A method for computing the similarity between two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. : NP\n",
      "Cupertino : NP\n",
      "California : NP\n",
      "it : NP\n",
      "Steve Jobs : NP\n"
     ]
    }
   ],
   "source": [
    "for te in doc.noun_chunks:\n",
    "    print(f\"{te.text} : {te.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Apple Inc., Cupertino, California, Steve Jobs)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. : ORG\n",
      "Cupertino : GPE\n",
      "California : GPE\n",
      "Steve Jobs : PERSON\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(f'{entity.text} : {entity.label_}')\n",
    "    \n",
    "y = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Volkswagen is developing an electric sedan which could potentially come to America next fall.\"\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-Speech Tagging\n",
    "\n",
    "Here we are just classifying how a word is used in a sentence e.g. {noun, verb, adjective}\n",
    "\n",
    "POS tags can be accessed through the **pos_** attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Volkswagen', 'PROPN'),\n",
       " ('is', 'AUX'),\n",
       " ('developing', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('electric', 'ADJ'),\n",
       " ('sedan', 'NOUN'),\n",
       " ('which', 'PRON'),\n",
       " ('could', 'AUX'),\n",
       " ('potentially', 'ADV'),\n",
       " ('come', 'VERB'),\n",
       " ('to', 'ADP'),\n",
       " ('America', 'PROPN'),\n",
       " ('next', 'ADJ'),\n",
       " ('fall', 'NOUN'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.text, t.pos_) for t in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a description we can use **spacy.explain()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access fine-grained tags though the **tag_** attribute. They provide more detailed information about a token such as its tense and, if a word is a pronoun, what type of a pronoun it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Volkswagen', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('developing', 'VBG'),\n",
       " ('an', 'DT'),\n",
       " ('electric', 'JJ'),\n",
       " ('sedan', 'NN'),\n",
       " ('which', 'WDT'),\n",
       " ('could', 'MD'),\n",
       " ('potentially', 'RB'),\n",
       " ('come', 'VB'),\n",
       " ('to', 'IN'),\n",
       " ('America', 'NNP'),\n",
       " ('next', 'JJ'),\n",
       " ('fall', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.text, t.tag_) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'verb, 3rd person singular present'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('VBZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Volkswagen', 'ORG'), ('America', 'GPE'), ('next fall', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "y = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Red Bull drops hint on F1 engine.\",\n",
    "    \"Honda exists F1, leaving F1 partner Red Bull.\",\n",
    "    \"Hamilton eyes record eighth F1 title.\",\n",
    "    \"Aston Martin announces sponsor.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Doc.png\">\n",
    "\n",
    "The **fit_transform** method performs 2 steps:\n",
    "- *fit*: learns a vocabulary dictionary from the corpus, i/e assign index values to each unique word in our vocabulary.\n",
    "\n",
    "<img src = \"fit_method.png\">\n",
    "\n",
    "- *transform*: creates a **BoW** matrix with appropriate token counts for each document. It returns a matrix where each row represents a document and each column represents a token (i.e. term).\n",
    "\n",
    "<img src = \"transform_method.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "bow = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **CountVectrizer** took care of tokenization for us, removed punction and lower-cased everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 8)\t2\n",
      "  (1, 11)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 15)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 19)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 13)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 18)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
